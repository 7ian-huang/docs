# 高性能网络编程初探
***
## 1 高性能编程分类
***实际生产中的程序一般分为CPU密集型和IO密集型，因此，高性能编程也分为两种：***


#### 1.1 CPU密集型优化策略
* 优化算法
* 采用编译型语言

#### 1.2 IO密集型优化策略
* 减少进程上下文切换
* 减少陷入内核的次数
* 减少锁的使用
* 减少内存拷贝

** \*本文档着重介绍IO密集型程序性能优化策略以及Python在高性能网络编程方面的应用\* **

## 2 IO效率低下的成因
#### 2.1 冯·诺依曼体系结构

![](http://a.hiphotos.baidu.com/baike/c0%3Dbaike80%2C5%2C5%2C80%2C26/sign=fd1cd3e89b25bc313f5009ca3fb6e6d4/8b82b9014a90f603a3649a613b12b31bb151edc4.jpg)

* 程序 = 数据 + 算法
* 算法 = 代码段
* 数据 = ~~数据段、堆（内存）~~ or 外部硬件（网卡、磁盘）

~~数据来源主要是内存的程序算作CPU密集型~~

数据来源主要是外部硬件的程序算作IO密集型

数据不在内存中，需要从外部硬件调入数据，这是IO密集型程序性能低下的主要原因。极端情况下，一个read网卡的操作可能导致整个程序挂起很长时间

	import requests
	
	# hang
	# 假设此时百度响应很慢，下一条语句执行了1个小时
	resp = requests.get('http://www.baidu.com/'， timeout=7200)
	# 一个小时后，程序恢复执行
	print (resp)

如果是爬取10000个网页，那么这种导致程序在等待数据期间挂起的阻塞式编程会使得爬取效率很低，10000个网页的总获取时间是所有网页的获取时间之和

#### 2.2 进程是计算机科学史上的重大发明
冯·诺依曼体系结构自诞生之日起就面临着输入输出造成的性能瓶颈，进程概念的出现有效缓解了输入输出带来的麻烦

进程出现之前：

* 每个程序都独占CPU，只有当这个程序执行完，才可以执行别的程序（DOS）
* 没有进程空间的概念
* 对硬件的访问不受控制
 
进程出现之后：

* 由内核管理所有进程，当某个进程需要的IO资源不存在的时候，进程被内核挂起
* 进程之间资源独立
* 内核隔离了进程对外部硬件的直接操作

#### 2.3 当前的编程环境

内核与进程是相伴而生的，内核不光虚拟出了进程这样一个概念，而且还管理进程的资源，让进程之间是相互隔离的，同时，内核还控制着所有硬件的访问，当进程需要某个硬件资源的时候(比如read网卡数据)，进程向内核提出需求，由内核代替进程来完成该请求:

	/* 系统调用read的原型 */
	read(int fildes, void *buf, size_t nbyte);


进程概念出现之后，程序员的编码方式并没有改变很多，但是，由于进程概念的引入，像上面爬取百度首页的进程被内核挂起后，op还可以打开其他终端，然后在其他终端进行操作。（而且，一些后台进程也一直在运行中）


**这就是我们目前的编程环境：**

1. 独占程序已经一去不复返
2. 进程是现代操作系统最基本的资源管理与调度单位
3. 借助进程概念，整个系统的IO吞吐率已经大幅度提高

借助内核主动挂起进程的能力，我们爬取10000个网页资源的程序可以通过一下子生成10000个进程，每个进程get一个url的方式实现，那么，10000个网页的总获取时间就等于响应最慢的那个网页的处理时间。

***但这远没有达到最大性能，这与UNIX进程模型有关***

## 3 UNIX进程模型
#### 3.1 进程是什么？
进程就是内核虚拟出来的一个抽象，内核用进程来组织相关的一簇资源，比如：可执行代码、数据、内存映射、已打开文件、权限等。Linux内核中用于描述进程的结构是struct task_struct。
#### 3.2 进程隔离
内存映射是实现进程隔离的核心手段，程序员看到的都是虚拟地址，虚拟地址被\*CPU\*映射为物理地址。当一个程序被内核加载进内核之后，内核会创建一个struct task_struct，并将一些物理页（一页=4k/8k，页是内核对物理内存的最小管理单位）映射为进程的虚拟地址，并创建进程虚拟地址到物理地址的映射表，那么内存映射过程如下：

	/* 假设map函数就是完成内存映射的代码，但是，map实际上是由CPU完成的 */
	read_addr = map(virtual_addr, 映射表)
	
由于CPU的map功能的存在，以及内核创建的映射表，使每个进程有自己独立的、线性的、实际又是映射到不同位置的虚拟地址空间。


#### 3.3 进程切换
当前进程：CPU中有一个寄存器专门用来缓存映射表，这个寄存器当前缓存的是哪个进程的映射表，那么这个进程就是**\*当前进程\***，Linux内核中，用current指针指向当前进程对应的struct task_struct。

那么，进程切换，实际上就是四步：

1. current指针指向新进程 （轻量）
2. 映射表切换 （重量）
3. 进程堆栈环境切换：eip、esp、eax、ebx、ecx、eflags等等等等等等 （重量）
4. 一级cache、二级cache刷新 （极重量）

由此可见，进程切换是一个**\*非常重\***的操作（尽管类UNIX的进程已经足够轻量），所以一个拥有大量网络连接的系统，如果采用阻塞模型，势必造成大量的进程切换操作

#### 3.4 内核如何进行进程切换？
* 借助硬件。开机启动后，内核由BIOS程序从硬盘load到内存中，然后BIOS程序将控制权移交给内核，内核进行自己的初始化。内核初始化过程中，会注册一些硬件中断的处理代码，比较重要的几个硬件中断是：时钟中断、硬盘中断、键盘中断。其中，时钟中断是进程切换的根本所在。内核初始化期间设置时钟芯片每隔20毫秒触发一个时钟中断，此中断被CPU捕捉之后，CPU就会保存当前执行环境（这里不是进程上下文切换，这里仅仅是堆栈切换），然后跳转到已经注册的时钟中断处理代码处执行，此段代码执行shedule，shedule选择一个合适的进程进行切换。（也可能不切换）

* 主动让出。任何可能造成阻塞的系统调用，都会主动让出CPU，引发进程切换
* ~~2.5版本Linux内核增加了内核态抢占，所以非阻塞调用也可能让出CPU~~

#### 3.5 推后执行与下半部
当read网卡数据造成阻塞，进程被内核挂起，网卡数据到来后，内核又重新调度该进程进入运行态。内核的“下半部”机制是唤醒已挂起进程的必要手段。

* 当网卡数据不存在时，内核会将进程置为\*可中断睡眠状态\*
* 内核会记录下该进程正在等待数据，将进程加入等待队列
* 当数据到来的时候，网卡向总线发出网卡中断
* 内核启动时候注册的网卡中断处理程序会被触发，在该程序中，内核将已经被挂起的进程置为运行态，并将数据copy_to_user到进程空间的buffer处
* 将进程加入可运行队列
* 调用schedule

进程读取磁盘文件的过程与此类似，不同点是进程会被内核设置为\*非可中断睡眠状态\*

#### 3.6 线程与进程的关系
在Linux中，线程在内核中的管理结构也是struct task_struct，Linux内核并不区分进程与线程。如果多个struct task_struct描述的**\*执行体\***拥有相同的内存映射表，那么：这几个执行体共同构成一个进程，每个执行体都是一个线程。

* 进程是资源管理的单位
* 执行体（task struct）是Linux内核唯一调度单位


## 4 阻塞引出的问题
#### 4.1 阻塞式网络编程模型的进化
* 主进程负责监听，当新连接到来时候，fork一个子进程处理该连接
* 主线程负责监听，当新连接到来时候，create一个线程处理该连接
* pre-fork进程池方式，预先fork一定量的子进程，当新连接到来的时候，选定一个子进程为之服务。（Apache）
* 线程池方式。类上。



#### 4.2 两个极端
1. 10000条连接全部是活跃的，那么Apache的worker就频繁地、依次地被内核调度执行
2. 10000条连接都不活跃，但是为了保持连接，Apache也产生了10000个进程服务于这些连接，这10000个进程占用大量内存，却无活可干

#### 总之：
一个struct task_struct结构服务于一条连接，当连接很多时，执行体就会增多，而执行体是一个很重量的单位，即耗费内存，而且调度起来很消耗总线周期

好处：

* 编码简单，所有操作均是阻塞
* 借助内核良好的进程隔离功能，单个worker崩溃不会影响到其他连接，而且也更加安全

坏处：

* 大量活跃连接时，进程上下文切换会很频繁（两个极端之1）
* 无法承载大量连接，因为内存有限（两个极端之2）

C10K problem对此有更详尽的描述（参见[C10K roblem](http://www.kegel.com/c10k.html)）


## 5 目前可用的与外部硬件交互的方式

* 阻塞
* 非阻塞、轮询
* IO多路复用(select,poll,epoll,KQueue)
* 传统的、基于信号的异步IO
* Native AIO

## 6 非阻塞、轮询
#### 6.1 非阻塞是文件描述符的属性
read一个非阻塞的网络套接字，而且此时并没有需要的数据的时候，内核不会挂起进程，但是由于数据不存在，所以read操作会失败
#### 6.2 轮询检查
轮询配合非阻塞，可以一定程度上解决阻塞带来的问题。

一个进程打开很多个连接，每个连接都置为非阻塞，定时去检查所有的链接。

优点：

* 编码相对简单

缺点：

* 实时性差，浪费CPU计算资源

## 7 IO多路复用
#### 7.1 IO多路复用不是什么新鲜玩意

* select已经出现很多年
* Linux内核2.5版本引入了epoll，epoll在内部实现上使用触发机制，效率远高于select
* BSD系列的UNIX使用KQueue作为事件通知接口

#### 7.2 IO多路复用的编程模式



	listenfd = listen();
	
	epollfd = epoll_create();
			
	add_fd_to_epoll(listenfd, epollfd, EPOLL_READ);
	
	while (1) {
		fd, event = epoll_wait();
		if (fd == listenfd) {
			conn = accept(fd);
			add_fd_to_epoll(conn, epollfd, EPOLL_READ);
		} else {
			if (event == EPOLL_READ) {
				buffer = generate_response(fd);
				assoc(fd, buffer);
				update_fd_in_epoll(fd, epollfd, EPOLL_WRITE);
			} else if (event == EPOLL_WRITE) {
				buffer = get_buffer(fd);
				send(fd, buffer);
				update_fd_in_epoll(fd, epollfd, EPOLL_READ);
			}
		}
	}

## 8 基于信号的异步
太老，没人用

## 9 Linux新引进的Native AIO（异步IO）
#### 9.1 2.4内核中的基于线程的AIO
拙劣的模拟，已被抛弃

#### 9.2 这才是真正意义上的异步（asynchronous）
![](http://img.blog.csdn.net/20140602194744468)

#### 9.3 Native AIO

* Native AIO与epoll不是对立的
* Native AIO与epoll合作，才能发挥最大性能（nginx）
* 内核对Native AIO的支持还不完善

分析：[Nginx引入线程池，性能提升9倍](http://www.infoq.com/cn/articles/thread-pools-boost-performance-9x/)


## 10 Python在高性能网络编程中的应用
* 包装epoll、KQueue
* 闭包 =》偏函数
* 生成器

## 11 Tornado框架基础概念
* ioloop
* connection
* request
* application
* RequestHandler

用tornado实现的hello，world！：

	import tornado.httpserver
	import tornado.ioloop
	import tornado.options
	import tornado.web

	from tornado.options import define, options
	define("port", default=8000, help="run on the given port", type=int)

	class IndexHandler(tornado.web.RequestHandler):
    	def get(self):
        	greeting = self.get_argument('greeting', 'Hello')
        	self.write(greeting + ', friendly user!')

	if __name__ == "__main__":
    	tornado.options.parse_command_line()
    	app = tornado.web.Application(handlers=[(r"/", IndexHandler)])
    	http_server = tornado.httpserver.HTTPServer(app)
    	http_server.listen(options.port)
    	tornado.ioloop.IOLoop.instance().start()
    	
## 12 Tornado的适用场景与使用限制

**适用场景：**

1. 大量在线
2. HTTP长轮询
3. websockets

**Tornado的问题：**

1. 让一切都异步会使编码难度陡然升高
2. DNS、数据库的异步支持不完善
3. Python性能太差

## 13 进一步优化
* 减少陷入内核的次数 (readv，尝试写)
* 内存分配策略的优化
* 减少磁盘读写
* 尽量不要用锁

## 14 实例分析-多线程、异步、加锁造成的不可维护
场景：

* 数据来源于上游
* 前端有大量连接 

技术点：

* 订阅模式（服务器推技术）
* 异步触发
* 等待队列
* 死链问题（业务死链、tcp死链）